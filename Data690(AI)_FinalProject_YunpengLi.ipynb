{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 690 (AI) Final Project\n",
    "## Facial Recognition Demo\n",
    "## Yunpeng Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to setup the directories we'll be storing our images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return None\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for extracting person faces from original photo in a source directory and save them to a destination directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFacesFromPictures(source_dir, dest_dir):\n",
    "    \n",
    "    makedir(dest_dir)\n",
    "    \n",
    "    # Loading HAARCascade Face Detector \n",
    "    faceDetector = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    imageNames = [f for f in listdir(source_dir) if isfile(join(source_dir, f))]\n",
    "    \n",
    "    for imageName in imageNames:\n",
    "        print(imageName)\n",
    "        image = cv2.imread(source_dir+imageName)\n",
    "        \n",
    "        cv2.imshow('imageName', image) \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        face_info = faceDetector.detectMultiScale(image, 1.3, 5)\n",
    "        \n",
    "        print(face_info)\n",
    "        for (x,y,w,h) in face_info:\n",
    "            face = image[y:y+h, x:x+w]\n",
    "            roi = cv2.resize(face, (128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "            cv2.imshow(\"face\", roi)\n",
    "            \n",
    "            path = dest_dir + \"face_\" + imageName \n",
    "            cv2.imwrite(path, roi) #Save the extracted faces into the destination directory\n",
    "            \n",
    "            cv2.waitKey(0)\n",
    "        \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Britney Spears.jpg\n",
      "[[403 307 830 830]]\n",
      "Dwayne Johnson (Rock).jpg\n",
      "[[ 67  63 185 185]]\n",
      "Hillary.jpg\n",
      "[[392 612 836 836]]\n",
      "Jenny.jpg\n",
      "[[ 57  86 192 192]]\n",
      "Kim Jong Un.jpg\n",
      "[[ 80  74 189 189]]\n",
      "Lady Gaga.jpg\n",
      "[[155  53 413 413]]\n",
      "Madonna.jpg\n",
      "[[507 171 516 516]]\n",
      "Trump.jpg\n",
      "[[1448  457  890  890]]\n",
      "Yunpeng.jpg\n",
      "[[664 252 218 218]]\n"
     ]
    }
   ],
   "source": [
    "extractFacesFromPictures('./images/', './faces/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use VGGFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#TODO\n",
    "#Download pretrained weights from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "\n",
    "#from tensorflow.keras.models import model_from_json\n",
    "model.load_weights('vgg_face_weights.h5')\n",
    "\n",
    "#Remove last Softmax layer and get model upto last flatten layer\n",
    "vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "\n",
    "vggFaceModel = vgg_face_descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VggFaceModel architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_26_input (Inp [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPaddi (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPaddi (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPaddi (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPaddi (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPaddi (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPaddi (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 1, 1, 2622)        10742334  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggFaceModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for loading image from path and resizes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and resizes it\"\"\"\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare images by Cosine Similiarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create presentation of each extraced face by VGGFaceModel prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_Britney Spears.jpg\n",
      "face_Dwayne Johnson (Rock).jpg\n",
      "face_Hillary.jpg\n",
      "face_Jenny.jpg\n",
      "face_Kim Jong Un.jpg\n",
      "face_Lady Gaga.jpg\n",
      "face_Madonna.jpg\n",
      "face_Trump.jpg\n",
      "face_Yunpeng.jpg\n"
     ]
    }
   ],
   "source": [
    "all_faces = dict()\n",
    "\n",
    "for file in listdir('./faces/'):\n",
    "    \n",
    "    print(file)\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_faces[person_face] = vggFaceModel.predict(preprocess_image('./faces/%s.jpg' % (person_face)))[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face_Britney Spears': array([ 1.60496   , -1.5575426 , -0.14216928, ...,  3.4180443 ,\n",
       "        -0.42121536,  0.14598373], dtype=float32),\n",
       " 'face_Dwayne Johnson (Rock)': array([ 3.9746056 , -2.6902373 , -0.30208504, ..., -1.9033624 ,\n",
       "         0.47788623,  0.14036633], dtype=float32),\n",
       " 'face_Hillary': array([ 1.0320519, -2.672826 , -3.1798182, ..., -2.312236 ,  0.9663745,\n",
       "         1.2726313], dtype=float32),\n",
       " 'face_Jenny': array([ 0.88640165,  1.1435761 ,  0.45120814, ..., -2.4543052 ,\n",
       "         2.3160427 ,  3.7199552 ], dtype=float32),\n",
       " 'face_Kim Jong Un': array([ 0.81118304, -1.084969  ,  0.1463707 , ..., -2.7813516 ,\n",
       "         4.306972  ,  0.53672796], dtype=float32),\n",
       " 'face_Lady Gaga': array([ 1.7031907 , -4.33134   , -2.6338637 , ..., -1.8551259 ,\n",
       "         0.06040401,  3.3642864 ], dtype=float32),\n",
       " 'face_Madonna': array([ 0.68289185, -0.9796021 ,  1.4411439 , ..., -4.76454   ,\n",
       "         2.0778015 ,  2.0321078 ], dtype=float32),\n",
       " 'face_Trump': array([ 2.4377742 , -0.18090715, -1.6431191 , ..., -1.5195199 ,\n",
       "        -1.0417398 , -0.7483742 ], dtype=float32),\n",
       " 'face_Yunpeng': array([ 2.6926615 ,  1.549706  , -0.86320007, ..., -2.8350484 ,\n",
       "         3.1759071 ,  0.5501715 ], dtype=float32)}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for using cv2.VideoCapture to recognize face similar to the face images stored in the face_database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(face_database, video_capture):\n",
    "    \n",
    "    # Loading HAARCascade Face Detector \n",
    "    faceDetector = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "    while(True):\n",
    "        ret, img = video_capture.read()\n",
    "        faces = faceDetector.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2) #draw rectangle to main image\n",
    "\n",
    "            detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "            detected_face = cv2.resize(detected_face, (224, 224)) #resize to 224x224\n",
    "\n",
    "            img_pixels = image.img_to_array(detected_face)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            img_pixels /= 255\n",
    "\n",
    "            captured_representation = vggFaceModel.predict(img_pixels)[0,:]\n",
    "\n",
    "            print(captured_representation)\n",
    "\n",
    "            found = False\n",
    "\n",
    "            # Compare captured face with the stored face\n",
    "            for face in face_database:\n",
    "                representation = face_database[face]\n",
    "                person_name=face[5:]\n",
    "\n",
    "                similarity = calculateCosineSimilarity(representation, captured_representation)\n",
    "\n",
    "                if(similarity < 0.25):\n",
    "                    cv2.putText(img, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            #connect face and text\n",
    "\n",
    "            cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "            cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "            if(found == False): #if found image is not in our people database\n",
    "                cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "\n",
    "        if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use webcam to detect and capture face in real time and compare it with the stored faces so as to recogize face:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01040188  0.00106935  0.00314128 ... -0.01295905  0.01894774\n",
      "  0.01196851]\n",
      "[ 0.01804194  0.00712961  0.00818555 ... -0.01505877  0.02321138\n",
      "  0.00406144]\n",
      "[ 0.01769135  0.005941    0.00462554 ... -0.01580085  0.02450629\n",
      "  0.00588839]\n",
      "[ 0.01719665  0.00710686  0.0076104  ... -0.01558237  0.02208028\n",
      "  0.00426522]\n",
      "[ 0.01786124  0.00679336  0.00428505 ... -0.01485613  0.02257449\n",
      "  0.00428969]\n",
      "[ 0.01829234  0.00800912  0.00765472 ... -0.0154951   0.02475243\n",
      "  0.00547959]\n",
      "[ 0.01561677  0.01027791 -0.00202604 ... -0.01717918  0.02423229\n",
      "  0.0119628 ]\n",
      "[ 0.02279359  0.013145    0.00650536 ... -0.01672066  0.02098855\n",
      "  0.02228116]\n",
      "[ 0.02058489  0.02043145  0.00314734 ... -0.02123448  0.0291664\n",
      "  0.01944316]\n",
      "[ 0.02091859  0.01752253 -0.00104183 ... -0.0208318   0.03015089\n",
      "  0.01601984]\n",
      "[ 0.01523335  0.01369027  0.0007772  ... -0.01969828  0.02599016\n",
      "  0.01723714]\n",
      "[ 0.01940145  0.0157293   0.00185146 ... -0.02004239  0.02689217\n",
      "  0.01685565]\n",
      "[ 0.01871081  0.01306288  0.00258835 ... -0.02064083  0.02589047\n",
      "  0.01708934]\n",
      "[ 0.01880661  0.01821076  0.00108133 ... -0.02026216  0.02787896\n",
      "  0.01841945]\n",
      "[ 0.01748723  0.01166375  0.00278935 ... -0.01932942  0.02454881\n",
      "  0.01523567]\n",
      "[ 0.01949818  0.01500012  0.00217722 ... -0.02170236  0.02750935\n",
      "  0.01800163]\n",
      "[ 0.01674989  0.01135514  0.00190272 ... -0.01775545  0.02474093\n",
      "  0.01393295]\n",
      "[ 0.0149791   0.01085358  0.00298027 ... -0.02132011  0.02113433\n",
      "  0.01216643]\n",
      "[ 0.01466457  0.01215895  0.00131333 ... -0.02009988  0.02138559\n",
      "  0.01269013]\n",
      "[ 0.02050906  0.01659215  0.0047271  ... -0.02464573  0.0249716\n",
      "  0.02006059]\n",
      "[ 0.02007904  0.00755878 -0.00163565 ... -0.02004815  0.01823016\n",
      "  0.01290153]\n"
     ]
    }
   ],
   "source": [
    "#Open Webcam\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "detect_face(all_faces, camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze recorded video to recognize faces in the video:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00296052 -0.00072332  0.00210925 ... -0.00253696  0.00412182\n",
      "  0.02561892]\n",
      "[ 0.00934224 -0.00051054  0.00173485 ... -0.02042681  0.0204794\n",
      "  0.0099755 ]\n",
      "[ 0.00217472 -0.00164675  0.00177252 ... -0.00423024  0.00332869\n",
      "  0.02605653]\n",
      "[ 0.01433773  0.00182296  0.00555621 ... -0.02348037  0.02430162\n",
      "  0.01101995]\n",
      "[ 0.00286887 -0.00174106  0.0008247  ... -0.00455105  0.00413421\n",
      "  0.0259352 ]\n",
      "[ 0.01175528  0.00115652  0.00395784 ... -0.02295435  0.02260291\n",
      "  0.01046151]\n",
      "[ 0.00367001 -0.00241869 -0.0006467  ... -0.00362563  0.00508426\n",
      "  0.02567327]\n",
      "[ 0.01161902  0.00201731  0.00372995 ... -0.02373979  0.02244275\n",
      "  0.01006952]\n",
      "[ 0.0028968  -0.0016458   0.00092645 ... -0.00330563  0.00419714\n",
      "  0.02647534]\n",
      "[ 0.0084905  -0.00100416  0.00177778 ... -0.02313355  0.02160888\n",
      "  0.01026437]\n",
      "[ 0.00324872 -0.00309848  0.00022815 ... -0.00373952  0.00392483\n",
      "  0.02759625]\n",
      "[ 0.01021929  0.00051542  0.00245499 ... -0.02339717  0.02276633\n",
      "  0.01082117]\n",
      "[ 0.00421457 -0.00110154  0.00165922 ... -0.00352115  0.00378645\n",
      "  0.02641943]\n",
      "[ 0.01198254  0.00146839  0.00327693 ... -0.02158015  0.02333236\n",
      "  0.01102696]\n",
      "[ 0.0038408  -0.00184586  0.00077035 ... -0.0032093   0.00392034\n",
      "  0.02606601]\n",
      "[ 0.01225689  0.00247361  0.00481541 ... -0.02082725  0.02529409\n",
      "  0.01279719]\n",
      "[ 0.00315126 -0.00221936  0.00112142 ... -0.00300823  0.00350906\n",
      "  0.02515562]\n",
      "[ 0.01280836  0.00123369  0.00344007 ... -0.02166612  0.02293269\n",
      "  0.01095594]\n",
      "[ 0.00265059 -0.00208543  0.00050075 ... -0.00301564  0.00463376\n",
      "  0.02597291]\n",
      "[ 0.01031928 -0.00049141  0.00262184 ... -0.02195324  0.02241725\n",
      "  0.01228709]\n"
     ]
    }
   ],
   "source": [
    "video_capture_1 = cv2.VideoCapture('./videos/1.mp4')\n",
    "\n",
    "detect_face(all_faces, video_capture_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00204057  0.00295777 -0.00256422 ... -0.00439538  0.00399822\n",
      "  0.00665387]\n",
      "[ 0.00066078  0.00366082 -0.00294143 ... -0.00251856  0.00107463\n",
      "  0.00347667]\n",
      "[ 0.00376614  0.00543297 -0.00363034 ...  0.00814521 -0.00106358\n",
      "  0.00525908]\n",
      "[ 0.00315803  0.00149208 -0.0046159  ...  0.00785645 -0.00203934\n",
      "  0.00371513]\n",
      "[ 0.00326062  0.00048386 -0.00281422 ...  0.01137358 -0.00629338\n",
      " -0.00102162]\n",
      "[ 0.00358567  0.00093809 -0.00363676 ...  0.00988024 -0.00555493\n",
      "  0.00036617]\n",
      "[ 0.00886141 -0.0020516  -0.00953427 ...  0.00418702  0.01173882\n",
      "  0.0176084 ]\n",
      "[ 0.00735998  0.00237411 -0.00332455 ...  0.01250444 -0.00498478\n",
      "  0.00503373]\n",
      "[ 0.01218766 -0.01426951 -0.01216068 ... -0.00154649  0.00614659\n",
      "  0.01182063]\n",
      "[ 0.00464262  0.00117292 -0.00215564 ...  0.01094957 -0.00627829\n",
      "  0.00054007]\n",
      "[ 0.01244994 -0.01671246 -0.01436989 ... -0.00226698  0.00693272\n",
      "  0.00834761]\n",
      "[ 0.00436163  0.00114548 -0.00357897 ...  0.01047354 -0.00587068\n",
      "  0.00032705]\n",
      "[ 0.01334499 -0.01789414 -0.01456963 ... -0.00253701  0.00630495\n",
      "  0.00753007]\n",
      "[ 0.00443006  0.0009377  -0.00419749 ...  0.01105759 -0.00554136\n",
      "  0.00120457]\n",
      "[ 0.01021599 -0.01625507 -0.01345175 ... -0.00313147  0.0058886\n",
      "  0.00786301]\n",
      "[ 0.00449351  0.00141036 -0.00539418 ...  0.01074184 -0.00570794\n",
      "  0.00153078]\n",
      "[ 0.00868752 -0.01181869 -0.00953979 ...  0.00227568  0.00779585\n",
      "  0.00710099]\n",
      "[ 0.0057151   0.00100855 -0.00360393 ...  0.01230461 -0.00600765\n",
      "  0.00025942]\n",
      "[ 0.00666885 -0.01371613 -0.01045829 ...  0.00136474  0.00966427\n",
      "  0.00715554]\n",
      "[ 0.00872477 -0.01178143 -0.01196235 ...  0.00112729  0.0081654\n",
      "  0.00741862]\n",
      "[ 0.00580366  0.00159519 -0.00238395 ...  0.01195064 -0.00372189\n",
      "  0.0008241 ]\n",
      "[ 0.00933009 -0.01258061 -0.01517771 ...  0.00032459  0.00639244\n",
      "  0.00980183]\n",
      "[ 0.00326712  0.00310253 -0.00155137 ...  0.00507299  0.00214303\n",
      "  0.00452005]\n",
      "[ 0.00735871  0.00519454 -0.0062506  ... -0.00157856  0.00518334\n",
      "  0.00710772]\n",
      "[ 0.00743601 -0.01312545 -0.01108257 ...  0.00050066  0.00794012\n",
      "  0.01025433]\n",
      "[ 0.00739694  0.00586765 -0.00459417 ...  0.00235875  0.00152401\n",
      "  0.00763338]\n",
      "[ 0.00684453 -0.01344147 -0.01514914 ...  0.00396101  0.00542009\n",
      "  0.00937809]\n",
      "[ 4.0131533e-03  3.7526730e-03 -2.9356258e-03 ...  2.3904238e-03\n",
      " -7.0375907e-05  1.1664859e-03]\n",
      "[ 0.00721098 -0.01417163 -0.01223693 ...  0.0057098   0.00837093\n",
      "  0.01224681]\n",
      "[ 0.00539269 -0.01302697 -0.01028698 ...  0.00567827  0.00950708\n",
      "  0.00977703]\n",
      "[ 0.00349992  0.00145009 -0.0041969  ...  0.00436355  0.00049428\n",
      "  0.00362049]\n",
      "[ 0.00756865 -0.0129155  -0.01296169 ...  0.00399893  0.00953544\n",
      "  0.01162843]\n",
      "[ 0.00555751  0.00138407 -0.00729918 ...  0.00231033 -0.00018089\n",
      "  0.00184551]\n",
      "[ 0.00755708 -0.01270619 -0.01402283 ...  0.00718183  0.00891168\n",
      "  0.01020765]\n",
      "[ 0.00859641 -0.01454393 -0.01330753 ...  0.00686166  0.00731599\n",
      "  0.00725044]\n",
      "[ 0.00886488  0.0042154  -0.00307645 ...  0.00066072  0.00535197\n",
      "  0.00745059]\n",
      "[ 0.01023129 -0.01564404 -0.01378857 ...  0.00352411  0.00849191\n",
      "  0.00877425]\n",
      "[ 0.01096879 -0.01537554 -0.01501871 ...  0.00387026  0.0082364\n",
      "  0.00780969]\n",
      "[ 0.00702073  0.0046876  -0.00419486 ... -0.00105412  0.00516328\n",
      "  0.00742486]\n",
      "[ 0.01093272 -0.01436678 -0.01454866 ...  0.00146705  0.00693999\n",
      "  0.0081003 ]\n",
      "[ 0.00795635  0.00578783 -0.00567054 ... -0.00034318  0.00153308\n",
      "  0.00369716]\n",
      "[ 0.00627826  0.00472501 -0.00610586 ... -0.00359592  0.00285678\n",
      "  0.0055996 ]\n",
      "[ 0.01044989 -0.01409221 -0.01137526 ...  0.00123315  0.00694835\n",
      "  0.00755319]\n",
      "[ 0.00817965  0.00831336 -0.00547616 ...  0.00030309  0.00187428\n",
      "  0.00489313]\n",
      "[ 0.00978175 -0.01453131 -0.01497208 ...  0.00383946  0.00907123\n",
      "  0.00926098]\n",
      "[ 0.00835507  0.00496001 -0.00569272 ...  0.00275882  0.00103136\n",
      "  0.00570203]\n",
      "[ 0.01015806 -0.01447376 -0.01400357 ...  0.00529258  0.00725345\n",
      "  0.00736899]\n",
      "[ 0.00800873  0.0045804  -0.00576234 ...  0.00351675  0.00144276\n",
      "  0.00528782]\n",
      "[ 0.00992516 -0.01572897 -0.01383513 ... -0.00081246  0.00867498\n",
      "  0.00884229]\n",
      "[ 0.00881326  0.00568343 -0.00530035 ...  0.00225949  0.00226884\n",
      "  0.00630344]\n",
      "[ 0.01053354 -0.01411512 -0.0133657  ...  0.00047691  0.0093052\n",
      "  0.00964796]\n",
      "[ 0.00898081  0.00368485 -0.00682353 ...  0.00098552  0.00218113\n",
      "  0.00558526]\n",
      "[ 0.01115226 -0.01258679 -0.01078873 ... -0.00147853  0.00447159\n",
      "  0.00586502]\n",
      "[ 0.00998639 -0.01254712 -0.01408834 ... -0.00313019  0.00543877\n",
      "  0.00716737]\n",
      "[ 0.00871789  0.00495024 -0.00542395 ...  0.00024458  0.00145834\n",
      "  0.00426355]\n",
      "[ 0.00754083  0.00380453 -0.0050276  ...  0.00203081 -0.00091758\n",
      "  0.00062406]\n",
      "[ 0.01017214 -0.01214686 -0.01315706 ... -0.00274577  0.00476372\n",
      "  0.00786768]\n",
      "[ 0.01256003 -0.01429188 -0.01523014 ... -0.00739019  0.00374235\n",
      "  0.00834579]\n",
      "[ 0.00400074  0.00317735 -0.0021221  ...  0.0099859  -0.00185644\n",
      " -0.00240031]\n",
      "[ 0.01244709 -0.01615276 -0.01511718 ... -0.00650448  0.0035678\n",
      "  0.01027392]\n",
      "[ 0.00551511  0.00466432 -0.004952   ...  0.00938543 -0.00342982\n",
      " -0.00186953]\n",
      "[ 0.01231614 -0.01577254 -0.01460882 ... -0.00655355  0.0037158\n",
      "  0.01003953]\n",
      "[ 0.00411332  0.00333686 -0.00248643 ... -0.00187264 -0.0022768\n",
      " -0.00429465]\n",
      "[ 0.01337564 -0.0141621  -0.01477574 ... -0.00565543  0.00398674\n",
      "  0.01166783]\n",
      "[ 0.00371216  0.00313926 -0.00238466 ... -0.00332253 -0.00095624\n",
      " -0.00236624]\n",
      "[ 0.01274503 -0.01386956 -0.01495502 ... -0.00463067  0.00399103\n",
      "  0.01182689]\n",
      "[ 0.00200862  0.00192828 -0.00399118 ... -0.00343365 -0.00140808\n",
      " -0.00097391]\n",
      "[ 0.01271486 -0.0150834  -0.01437869 ... -0.00295516  0.00326074\n",
      "  0.01030531]\n",
      "[ 0.00244739  0.00315807 -0.00382554 ... -0.00404789 -0.00041018\n",
      "  0.00129951]\n",
      "[ 0.01268622 -0.01571084 -0.01372591 ... -0.00165445  0.00449906\n",
      "  0.00948723]\n",
      "[ 3.8934306e-03  3.6292546e-04 -2.7485751e-03 ...  5.2471220e-04\n",
      " -1.9983107e-03  4.0114654e-05]\n",
      "[ 0.01174193 -0.01548269 -0.0144845  ... -0.00155766  0.00290663\n",
      "  0.00980786]\n",
      "[ 0.0042121   0.003356   -0.00515244 ... -0.00585639 -0.00089266\n",
      "  0.00265717]\n",
      "[ 0.01341764 -0.01474414 -0.01460075 ... -0.00242716  0.00427397\n",
      "  0.01128315]\n",
      "[ 0.00480712  0.00050048 -0.00421669 ... -0.00037978 -0.00165419\n",
      "  0.00373925]\n"
     ]
    }
   ],
   "source": [
    "video_capture_2 = cv2.VideoCapture('./videos/2.mp4')\n",
    "\n",
    "detect_face(all_faces, video_capture_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00284104 -0.00774925  0.00690357 ... -0.01010167  0.01483792\n",
      "  0.00810243]\n",
      "[ 0.00397602  0.00715183 -0.00297459 ... -0.00515174  0.00111554\n",
      "  0.00359487]\n",
      "[ 0.00301588 -0.0078433   0.00559551 ... -0.01057601  0.01412831\n",
      "  0.00805489]\n",
      "[ 0.00489471  0.00601196 -0.00580766 ... -0.00187974 -0.00241028\n",
      "  0.00062992]\n",
      "[ 0.00799976  0.00476745 -0.00421184 ...  0.00028382 -0.00072314\n",
      "  0.00098995]\n",
      "[ 0.0038297  -0.00919363  0.00696561 ... -0.00919779  0.01425986\n",
      "  0.00731399]\n",
      "[ 0.00725941  0.00503019 -0.0044192  ... -0.00362337  0.00010075\n",
      "  0.00281231]\n",
      "[ 0.00201305 -0.01030707  0.00652388 ... -0.01187971  0.01503764\n",
      "  0.00770207]\n",
      "[ 0.00750658  0.00682887 -0.00273739 ... -0.00193884 -0.00101493\n",
      "  0.00188053]\n",
      "[ 0.00321054 -0.00972073  0.00922822 ... -0.01198062  0.01535834\n",
      "  0.00775328]\n",
      "[ 0.00151104 -0.01070017  0.00759787 ... -0.01275997  0.01478824\n",
      "  0.00770627]\n",
      "[ 0.00709849  0.0056701  -0.00211996 ... -0.00139352 -0.00164533\n",
      "  0.00154553]\n",
      "[ 0.00160525 -0.01158241  0.00710596 ... -0.01302548  0.01440716\n",
      "  0.00711935]\n",
      "[ 0.00870406  0.00895066  0.00563959 ... -0.00209035  0.01148389\n",
      "  0.01091987]\n",
      "[ 0.00556893  0.00771427 -0.0012106  ... -0.00152496 -0.00184708\n",
      "  0.0023691 ]\n",
      "[ 0.00251652 -0.01078696  0.00773367 ... -0.0136444   0.01528628\n",
      "  0.00782162]\n",
      "[ 0.00857034  0.00881861  0.0054248  ... -0.00216635  0.01152855\n",
      "  0.01120665]\n",
      "[ 0.00615877  0.01238765 -0.00379663 ... -0.00128457 -0.00394625\n",
      "  0.00070649]\n",
      "[ 0.00229414 -0.01086546  0.00768819 ... -0.01372438  0.01540236\n",
      "  0.00792642]\n",
      "[ 0.00514901  0.00634224 -0.0036558  ...  0.00312682 -0.00358741\n",
      " -0.00199014]\n",
      "[ 0.00136705 -0.01130209  0.00707139 ... -0.01286964  0.01443941\n",
      "  0.00766057]\n",
      "[ 0.00223104  0.00638679 -0.00353114 ...  0.00255432  0.00301132\n",
      " -0.00198584]\n",
      "[ 0.00245644 -0.01040922  0.00802966 ... -0.01319909  0.01489838\n",
      "  0.00751025]\n",
      "[ 0.00192996  0.00593623 -0.00350824 ...  0.00267537  0.00392843\n",
      " -0.00135895]\n",
      "[ 0.00250081 -0.01018458  0.00800854 ... -0.01294412  0.01505125\n",
      "  0.00769885]\n",
      "[-0.00181265  0.00414439 -0.00238232 ... -0.00076201  0.00183299\n",
      " -0.00248145]\n",
      "[ 0.00251318 -0.01023828  0.00812977 ... -0.01312807  0.01502972\n",
      "  0.00762997]\n",
      "[ 0.00035044  0.0042459  -0.00131674 ...  0.00351931  0.00173989\n",
      " -0.00158629]\n",
      "[ 0.00151491 -0.01039429  0.00681907 ... -0.01236885  0.0139867\n",
      "  0.00706036]\n",
      "[ 3.9281929e-04  4.7452557e-03  4.5321864e-04 ...  1.5810672e-03\n",
      "  9.5327850e-05 -2.5837631e-03]\n",
      "[ 0.00154013 -0.01030501  0.00683107 ... -0.01235804  0.01397724\n",
      "  0.00697606]\n",
      "[ 0.00061221  0.00716428  0.00093784 ... -0.00028257 -0.00183134\n",
      " -0.00220727]\n",
      "[ 0.00155606 -0.01031132  0.00684358 ... -0.0123607   0.01399966\n",
      "  0.00697313]\n",
      "[ 0.00183462  0.00994661  0.00106252 ...  0.00154006 -0.00043463\n",
      " -0.00115163]\n",
      "[ 0.00250763 -0.01065437  0.00719701 ... -0.01335183  0.01486562\n",
      "  0.00724221]\n",
      "[ 0.00059418  0.00495982 -0.00097291 ...  0.00171636 -0.00302765\n",
      " -0.00399907]\n"
     ]
    }
   ],
   "source": [
    "video_capture_3 = cv2.VideoCapture('./videos/3.mp4')\n",
    "\n",
    "detect_face(all_faces, video_capture_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release camera or video caputure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "video_capture_1.release()\n",
    "video_capture_2.release()\n",
    "video_capture_3.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
